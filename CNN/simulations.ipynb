{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759d9541",
   "metadata": {},
   "source": [
    "### Simulations\n",
    "The objective is to run the model based on it's own predicted data, so we get a continuous running simulation. \n",
    "We'll run an hour by hour simulation for 24 hours and compare to the bechmark model that comutes the 24 hour prediction at once. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8655f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from cnn_model_yin import CNN, cross_validate, train\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))  # add parent directory to sys.path\n",
    "from data_cleanup import DataProcessor\n",
    "\n",
    "# Reproducibility (best-effort)\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d14228",
   "metadata": {},
   "source": [
    "To run a simulation we need to compute a prediction for every input feature, that's why we don't use a flat layer, instead we let the final convolutional layer to compute the prediction for every feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7b64ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HourlyCNN(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(HourlyCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=8, out_channels=32, kernel_size=6)  \n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5) \n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=4) \n",
    "        self.conv4 = nn.Conv1d(in_channels=32, out_channels=8, kernel_size=1)\n",
    "        # Collapse time dimension → exactly 1 step\n",
    "        self.pool = nn.AdaptiveAvgPool1d(output_size=1)\n",
    "\n",
    "        # get output shape: \n",
    "        with torch.no_grad():\n",
    "            test_input = torch.randn(1, 8, 24)\n",
    "            test_output = self.conv1(test_input)\n",
    "            test_output = self.conv2(test_output)\n",
    "            test_output = self.conv3(test_output)\n",
    "            test_output = self.conv4(test_output)\n",
    "            test_output = self.pool(test_output)\n",
    "            \n",
    "            print(test_output.shape) # [1, 8, 1]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f0970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_hourly(input_steps, output_steps_size, model):\n",
    "    \n",
    "    running_input = input_steps.clone()  # shape [8, 24]\n",
    "    sim_outputs = [] \n",
    "\n",
    "    for _ in range(output_steps_size):\n",
    "\n",
    "        # model expects shape [1, C, T]\n",
    "        inp = running_input.unsqueeze(0)\n",
    "\n",
    "        # predict next hour\n",
    "        output = model(inp).squeeze(0)   # shape [8, 1] or [8] depending on model\n",
    "\n",
    "        # ensure output is [8, 1]\n",
    "        if output.ndim == 1:\n",
    "            output = output.unsqueeze(1)\n",
    "\n",
    "        sim_outputs.append(output)\n",
    "\n",
    "        # append new prediction and remove oldest timestep\n",
    "        running_input = torch.cat([running_input, output], dim=1)[:, 1:]\n",
    "\n",
    "    # concatenate all simulated timesteps → [8, output_steps_size]\n",
    "    return torch.cat(sim_outputs, dim=1)\n",
    "\n",
    "    \n",
    "# build a cumulative error function\n",
    "def point_mse_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    y_true, y_pred: tensors shaped [channels=8, time]\n",
    "    Computes MSE only on channel 1.\n",
    "    \"\"\"\n",
    "    diff = y_true[1] - y_pred[1]\n",
    "    return torch.mean(diff ** 2).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3824f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "INPUT_STEPS = 24\n",
    "OUTPUT_STEPS = 1\n",
    "\n",
    "processor = DataProcessor(input_steps=INPUT_STEPS, output_steps=OUTPUT_STEPS)\n",
    "Train, Val, Test = processor.load_and_process_data()\n",
    "\n",
    "X_train, y_train = Train\n",
    "X_val, y_val = Val\n",
    "X_test, y_test = Test\n",
    "\n",
    "model = HourlyCNN()\n",
    "\n",
    "# print model num_params\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \", num_params)\n",
    "\n",
    "history = train(model, X_train, y_train, X_val, y_val, epochs=20)\n",
    "\n",
    "# plot history\n",
    "plt.plot(history['train_loss'], label='train')\n",
    "plt.plot(history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404e9a33",
   "metadata": {},
   "source": [
    "Now to test the model, we need to generate 24 hour label features, to be compared with the simulated ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5702067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model:\n",
    "processor = DataProcessor(input_steps=24, output_steps=24, get_all_label_features=True) \n",
    "Train, Val, Test = processor.load_and_process_data() \n",
    "X_train, y_train = Train\n",
    "X_val, y_val = Val\n",
    "X_test, y_test = Test\n",
    "\n",
    "# convert test data\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# create a test loader\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=torch.utils.data.TensorDataset(X_test_t, y_test_t),\n",
    "    batch_size=4,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06509a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute errors\n",
    "\n",
    "total_cumulative_error = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.permute(0, 2, 1)\n",
    "        labels = labels.permute(0, 2, 1)\n",
    "        for i in range(len(inputs)):\n",
    "            sim_result = sim_hourly(inputs[i], 24, model)\n",
    "            total_cumulative_error += point_mse_error(sim_result, labels[i])\n",
    "\n",
    "\n",
    "mean_error = total_cumulative_error / len(test_loader.dataset)\n",
    "model.train()  # go back to training mode\n",
    "\n",
    "print(\"Cumulative Error: %.3f\" % total_cumulative_error)\n",
    "print(\"Mean Error: %.3f\" % mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70668e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets look at a sample: \n",
    "\n",
    "sample_batch_input, sample_batch_label = next(iter(test_loader))\n",
    "sample_batch_input = sample_batch_input.permute(0, 2, 1)\n",
    "sample_batch_label = sample_batch_label.permute(0, 2, 1)\n",
    "print(sample_batch_input.shape)\n",
    "print(sample_batch_label.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    sim = sim_hourly(sample_batch_input[0], 24, hourly_net)\n",
    "# print(sim.shape)\n",
    "print(sim.shape)\n",
    "\n",
    "# plt.plot(sample_batch_input[0][1].numpy())\n",
    "plt.plot(sim[0].numpy(), label=\"Sim\")\n",
    "plt.plot(sample_batch_label[0][0].numpy(), label=\"Label\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
