{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f1f66b4",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b132c2",
   "metadata": {},
   "source": [
    "This is a basic convolutional approach to sequence prediction using convolutions through PyTorch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92edc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os, sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21949708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data through the data preprocessor\n",
    "sys.path.append(os.path.abspath('..'))  # add parent directory to sys.path\n",
    "from data_cleanup import DataProcessor\n",
    "\n",
    "processor = DataProcessor(input_steps=24, output_steps=1) # get 24 hour sequences, and a 1 hour output\n",
    "Train, Val, Test = processor.load_and_process_data()\n",
    "\n",
    "X_train, y_train = Train\n",
    "X_val, y_val = Val\n",
    "X_test, y_test = Test\n",
    "\n",
    "print(f\"Train: \\n \\t X: {X_train.shape}, y: {y_train.shape}\")\n",
    "print(f\"Val: \\n \\t X: {X_val.shape}, y: {y_val.shape}\")\n",
    "print(f\"Test: \\n \\t X: {X_test.shape}, y: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf9e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0].shape)\n",
    "print(f\"Sample tuple\\n {X_train[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5530b75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural Network: \n",
    "# The input will be a sequence of 24 hours of data, with 8 features/channels\n",
    "# Slide a window through the hours and create data for the next layer \n",
    "\n",
    "class CNN(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__() # Inherit from nn.Module\n",
    "        # Define layers: 3 convolutions (1D) and 2 fully connected layers (very standard)\n",
    "        self.conv1 = nn.Conv1d(in_channels=8, out_channels=32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=20, kernel_size=3)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2) # reusable pool layer\n",
    "        self.fc1 = nn.Linear(in_features=(20), out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ee8955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "epochs = 10\n",
    "\n",
    "net = CNN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "# turn data into torch tensors\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_t, y_train_t)\n",
    "\n",
    "# use DataLoader, an iterable object from pytorch, that helps with batch training\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        # the inputs are given like (batch, time, features),\n",
    "        # but the model expects (batch, features, time), permutate it: \n",
    "        inputs = inputs.permute(0, 2, 1)  \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fe6eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now validate: \n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test_t, y_test_t)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    for data, label in test_loader:\n",
    "        data = data.permute(0, 2, 1)\n",
    "        y_pred = net(data)\n",
    "        test_loss += F.mse_loss(y_pred, label)\n",
    "\n",
    "print(f\"Test Loss: {test_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b94899",
   "metadata": {},
   "source": [
    "hmmmmmm overfitting ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62186dc5",
   "metadata": {},
   "source": [
    "#### Pickle "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae283681",
   "metadata": {},
   "source": [
    "Saving the model to pickle. This makes it easy to load the model later, if you guys want to test it out, or have your model being tested by somebody else! Pickle is a library that lets you store python objects in a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f7e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('net.pkl', 'wb') as f:\n",
    "    pickle.dump(net, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6132bbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load it in the notebook\n",
    "with open('net.pkl', 'rb') as file:\n",
    "    net = pickle.load(file)\n",
    "\n",
    "# that's it now use 'net' as you would normally "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
