{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f1f66b4",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b132c2",
   "metadata": {},
   "source": [
    "This is a basic convolutional approach to sequence prediction using convolutions through PyTorch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e92edc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os, sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21949708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1/5: Fetching, cleaning, and engineering features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felipejaracaceres/Documents/UCD/Machine Learning/ECS171G13/venv/lib/python3.11/site-packages/ucimlrepo/fetch.py:97: DtypeWarning: Columns (2,3,4,5,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_url)\n",
      "/Users/felipejaracaceres/Documents/UCD/Machine Learning/ECS171G13/data_cleanup.py:77: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2/5: Resampling data to hourly and setting 'Global_active_power' as target...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felipejaracaceres/Documents/UCD/Machine Learning/ECS171G13/data_cleanup.py:117: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_hourly = df.resample('H').agg(agg_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3/5: Splitting data and applying scaler...\n",
      "Step 4/5: Creating time-series windows...\n",
      "Step 5/5: Data processing complete.\n",
      "Train: \n",
      " \t X: (25903, 24, 8), y: (25903, 1)\n",
      "Val: \n",
      " \t X: (3600, 24, 8), y: (3600, 1)\n",
      "Test: \n",
      " \t X: (5014, 24, 8), y: (5014, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felipejaracaceres/Documents/UCD/Machine Learning/ECS171G13/data_cleanup.py:118: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_hourly = df_hourly.fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# load data through the data preprocessor\n",
    "sys.path.append(os.path.abspath('..'))  # add parent directory to sys.path\n",
    "from data_cleanup import DataProcessor\n",
    "\n",
    "processor = DataProcessor(input_steps=24, output_steps=1) # get 24 hour sequences, and a 1 hour output\n",
    "Train, Val, Test = processor.load_and_process_data()\n",
    "\n",
    "X_train, y_train = Train\n",
    "X_val, y_val = Val\n",
    "X_test, y_test = Test\n",
    "\n",
    "print(f\"Train: \\n \\t X: {X_train.shape}, y: {y_train.shape}\")\n",
    "print(f\"Val: \\n \\t X: {X_val.shape}, y: {y_val.shape}\")\n",
    "print(f\"Test: \\n \\t X: {X_test.shape}, y: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9cf9e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 8)\n",
      "Sample tuple\n",
      " [[0.63681623 0.27607416 0.33794529 0.63115734 0.         0.00681981\n",
      "  0.49470253 0.47923051]\n",
      " [0.54504495 0.07832205 0.33550078 0.54148733 0.         0.14465183\n",
      "  0.82477588 0.56052221]\n",
      " [0.50900588 0.08522501 0.28380167 0.50215208 0.         0.03086863\n",
      "  0.81581092 0.58574856]\n",
      " [0.48854974 0.07177309 0.31598734 0.48110952 0.         0.\n",
      "  0.8207009  0.57217659]\n",
      " [0.45559722 0.07385283 0.43441706 0.44990435 0.         0.00897344\n",
      "  0.84189079 0.50306464]\n",
      " [0.32255458 0.04663923 0.49584732 0.32352941 0.         0.0028715\n",
      "  0.21678892 0.48406388]\n",
      " [0.30103161 0.06690562 0.56718775 0.30105213 0.         0.00179469\n",
      "  0.         0.51833529]\n",
      " [0.27320089 0.10805788 0.58031393 0.27343376 0.         0.01005025\n",
      "  0.         0.46523825]\n",
      " [0.50110826 0.15385637 0.56061507 0.49294596 0.         0.54343144\n",
      "  0.         0.46022976]\n",
      " [0.2273377  0.07593256 0.7666315  0.22835964 0.         0.01220388\n",
      "  0.         0.38611807]\n",
      " [0.23897957 0.0776583  0.71656277 0.2404352  0.         0.01651113\n",
      "  0.         0.4026496 ]\n",
      " [0.32498343 0.0961547  0.69132061 0.31671449 0.         0.01220388\n",
      "  0.43439283 0.41120432]\n",
      " [0.29095372 0.0520377  0.68574534 0.28921569 0.         0.00358938\n",
      "  0.22738386 0.42669387]\n",
      " [0.18321975 0.09796894 0.70229213 0.18029651 0.         0.01543431\n",
      "  0.         0.30916064]\n",
      " [0.23242843 0.05146245 0.61421949 0.22596844 0.         0.00358938\n",
      "  0.         0.40102972]\n",
      " [0.27445934 0.12947476 0.59372782 0.27068388 0.         0.01615219\n",
      "  0.         0.46290037]\n",
      " [0.37676596 0.07726006 0.49921678 0.37553802 0.         0.15757358\n",
      "  0.         0.53238009]\n",
      " [0.54453225 0.23040843 0.36852402 0.53909613 0.18366644 0.48133525\n",
      "  0.78973105 0.18454372]\n",
      " [0.36463728 0.23850613 0.42544036 0.35832138 0.19538249 0.1080402\n",
      "  0.8402608  0.12835578]\n",
      " [0.27839002 0.36240542 0.45843164 0.27379244 0.         0.011486\n",
      "  0.84678077 0.20003327]\n",
      " [0.23875689 0.1997876  0.54037275 0.2302726  0.         0.00107681\n",
      "  0.86145069 0.1359123 ]\n",
      " [0.30585305 0.31377495 0.69861577 0.29041129 0.         0.00717875\n",
      "  0.89160554 0.23517153]\n",
      " [0.44455608 0.08969423 0.56186183 0.42766619 0.14403859 0.00430725\n",
      "  0.86552567 0.3703921 ]\n",
      " [0.49747794 0.0957122  0.419961   0.48433764 0.17746382 0.00143575\n",
      "  0.8394458  0.44489782]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].shape)\n",
    "print(f\"Sample tuple\\n {X_train[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5530b75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural Network: \n",
    "# The input will be a sequence of 24 hours of data, with 8 features/channels\n",
    "# Slide a window through the hours and create data for the next layer \n",
    "\n",
    "class CNN(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__() # Inherit from nn.Module\n",
    "        # Define layers: 3 convolutions (1D) and 2 fully connected layers (very standard)\n",
    "        self.conv1 = nn.Conv1d(in_channels=8, out_channels=32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=20, kernel_size=3)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2) # reusable pool layer\n",
    "        self.fc1 = nn.Linear(in_features=(20), out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97ee8955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.021\n",
      "[1,  4000] loss: 0.020\n",
      "[1,  6000] loss: 0.020\n",
      "[2,  2000] loss: 0.019\n",
      "[2,  4000] loss: 0.018\n",
      "[2,  6000] loss: 0.017\n",
      "[3,  2000] loss: 0.017\n",
      "[3,  4000] loss: 0.016\n",
      "[3,  6000] loss: 0.017\n",
      "[4,  2000] loss: 0.016\n",
      "[4,  4000] loss: 0.015\n",
      "[4,  6000] loss: 0.015\n",
      "[5,  2000] loss: 0.015\n",
      "[5,  4000] loss: 0.014\n",
      "[5,  6000] loss: 0.015\n",
      "[6,  2000] loss: 0.015\n",
      "[6,  4000] loss: 0.015\n",
      "[6,  6000] loss: 0.014\n",
      "[7,  2000] loss: 0.014\n",
      "[7,  4000] loss: 0.014\n",
      "[7,  6000] loss: 0.014\n",
      "[8,  2000] loss: 0.014\n",
      "[8,  4000] loss: 0.014\n",
      "[8,  6000] loss: 0.014\n",
      "[9,  2000] loss: 0.013\n",
      "[9,  4000] loss: 0.014\n",
      "[9,  6000] loss: 0.014\n",
      "[10,  2000] loss: 0.013\n",
      "[10,  4000] loss: 0.014\n",
      "[10,  6000] loss: 0.013\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "epochs = 10\n",
    "\n",
    "net = CNN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "# turn data into torch tensors\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_t, y_train_t)\n",
    "\n",
    "# use DataLoader, an iterable object from pytorch, that helps with batch training\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        # the inputs are given like (batch, time, features),\n",
    "        # but the model expects (batch, features, time), permutate it: \n",
    "        inputs = inputs.permute(0, 2, 1)  \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8fe6eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.336254596710205\n"
     ]
    }
   ],
   "source": [
    "# now validate: \n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test_t, y_test_t)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    for data, label in test_loader:\n",
    "        data = data.permute(0, 2, 1)\n",
    "        y_pred = net(data)\n",
    "        test_loss += F.mse_loss(y_pred, label)\n",
    "\n",
    "print(f\"Test Loss: {test_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b94899",
   "metadata": {},
   "source": [
    "hmmmmmm overfitting ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62186dc5",
   "metadata": {},
   "source": [
    "#### Pickle "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae283681",
   "metadata": {},
   "source": [
    "Saving the model to pickle. This makes it easy to load the model later, if you guys want to test it out, or have your model being tested by somebody else! Pickle is a library that lets you store python objects in a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2f7e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('net.pkl', 'wb') as f:\n",
    "    pickle.dump(net, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6132bbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load it in the notebook\n",
    "with open('net.pkl', 'rb') as file:\n",
    "    net = pickle.load(file)\n",
    "\n",
    "# that's it now use 'net' as you would normally "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
